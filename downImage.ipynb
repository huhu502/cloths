{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import urllib3\n",
    "import multiprocessing\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from urllib3.util import Retry\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "Original script by Nicolas Lecoy (https://www.kaggle.com/nlecoy/imaterialist-downloader-util)\n",
    "\"\"\"\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "\n",
    "def download_image(fnames_and_urls):\n",
    "    \"\"\"\n",
    "    download image and save its with 90% quality as JPG format\n",
    "    skip image downloading if image already exists at given path\n",
    "    :param fnames_and_urls: tuple containing absolute path and url of image\n",
    "    \"\"\"\n",
    "    fname, url = fnames_and_urls\n",
    "    if not os.path.exists(fname):\n",
    "        http = urllib3.PoolManager(retries=Retry(connect=3, read=2, redirect=3))\n",
    "        response = http.request(\"GET\", url)\n",
    "        image = Image.open(io.BytesIO(response.data))\n",
    "        image_rgb = image.convert(\"RGB\")\n",
    "        image_rgb.save(fname, format='JPEG', quality=90)\n",
    "\n",
    "\n",
    "def parse_dataset(_dataset, _outdir, _max=10000):\n",
    "    \"\"\"\n",
    "    parse the dataset to create a list of tuple containing absolute path and url of image\n",
    "    :param _dataset: dataset to parse\n",
    "    :param _outdir: output directory where data will be saved\n",
    "    :param _max: maximum images to download (change to download all dataset)\n",
    "    :return: list of tuple containing absolute path and url of image\n",
    "    \"\"\"\n",
    "    _fnames_urls = []\n",
    "    with open(_dataset, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        for image in data[\"images\"]:\n",
    "            url = image[\"url\"]\n",
    "            fname = os.path.join(_outdir, \"{}.jpg\".format(image[\"imageId\"]))\n",
    "            _fnames_urls.append((fname, url))\n",
    "    if _max == None:\n",
    "        return _fnames_urls\n",
    "    return _fnames_urls[:_max]\n",
    "\n",
    "\n",
    "def download(outdir, nb_images=None, set_name=\"train\", quality=100):\n",
    "    if set_name not in [\"train\",\"validation\",\"test\"]:\n",
    "        raise ValueError('Wrong set name (must be in \"train\",\"validation\",\"test\")')\n",
    "\n",
    "    if not os.path.exists(outdir):\n",
    "        os.makedirs(outdir)\n",
    "\n",
    "    # parse json dataset file\n",
    "    baselink = \".\"\n",
    "    fnames_urls = parse_dataset(os.path.join(baselink, set_name + \".json\"), outdir, nb_images)\n",
    "\n",
    "    # download data\n",
    "    pool = multiprocessing.Pool(processes=12)\n",
    "    with tqdm(total=len(fnames_urls)) as progress_bar:\n",
    "        for _ in pool.imap_unordered(download_image, fnames_urls):\n",
    "            progress_bar.update(1)\n",
    "\n",
    "\n",
    "imagePath=\"train\"\n",
    "\n",
    "download(\"tmp/\"+imagePath, nb_images = 8713, set_name = imagePath, quality = 90)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
